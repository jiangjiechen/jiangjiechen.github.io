<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Explainable NLP | Jiangjie Chen</title>
    <link>https://jiangjiechen.github.io/tag/explainable-nlp/</link>
      <atom:link href="https://jiangjiechen.github.io/tag/explainable-nlp/index.xml" rel="self" type="application/rss+xml" />
    <description>Explainable NLP</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 21 May 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://jiangjiechen.github.io/media/icon_hua9f9b78e35233aa477f7219cbf68418f_67044_512x512_fill_lanczos_center_3.png</url>
      <title>Explainable NLP</title>
      <link>https://jiangjiechen.github.io/tag/explainable-nlp/</link>
    </image>
    
    <item>
      <title>Beneath Surface Similarity: Large Language Models Make Reasonable Scientific Analogies after Structure Abduction</title>
      <link>https://jiangjiechen.github.io/publication/scar/</link>
      <pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate>
      <guid>https://jiangjiechen.github.io/publication/scar/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Unsupervised Explanation Generation via Correct Instantiations</title>
      <link>https://jiangjiechen.github.io/publication/neon/</link>
      <pubDate>Tue, 22 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://jiangjiechen.github.io/publication/neon/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Theme I - Text Reasoning, Being Right for the Right Reasons ðŸ¤”</title>
      <link>https://jiangjiechen.github.io/projects/reasoning/</link>
      <pubDate>Sun, 27 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://jiangjiechen.github.io/projects/reasoning/</guid>
      <description>&lt;p&gt;For humans, intuitive inferences are made every now and then.
However, it would require reasons for humans to convince others and justify themselves of their inferences or decisions.
How can machines better convince humans of their predictions?
The key may lie in making the right and faithful reasons for self-justification.&lt;/p&gt;
&lt;p&gt;What is human-like reasoning? What is the holy grail of machine cognition?
It is easy to be right due to various spurious correlations, but it would require some actual reasoning skills to be right for the right and faithful reasons.
More importantly, symbolic reasoning is too fragile to handle everyday reasoning.
Can machine reasoning happen over natural language like humans do?&lt;/p&gt;
&lt;p&gt;Exemplar papers in this theme include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://jiangjiechen.github.io/publication/neon&#34;&gt;NEON (AAAI 2023)&lt;/a&gt;: a two-phrase, unsupervised explanation generation framework for explaining why a statement is wrong;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jiangjiechen.github.io/publication/ekar/&#34;&gt;E-KAR (Findings of ACL 2022)&lt;/a&gt;: a benchmark for analogical reasoning with free-text rationales for both positive and negative candidate answers;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jiangjiechen.github.io/publication/loren/&#34;&gt;LOREN (AAAI 2022)&lt;/a&gt;: generating faithful and accurate rationales without supervision;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jiangjiechen.github.io/publication/educat/&#34;&gt;EDUCAT (AAAI 2022)&lt;/a&gt;: unsupervised counterfactual reasoning for imagining possible outcomes;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jiangjiechen.github.io/publication/probr/&#34;&gt;PRobr (Findings of ACL 2021)&lt;/a&gt;: reasoning over natural language statements via an induced graphical model.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>E-KAR: A Benchmark for Rationalizing Natural Language Analogical Reasoning</title>
      <link>https://jiangjiechen.github.io/publication/ekar/</link>
      <pubDate>Thu, 24 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://jiangjiechen.github.io/publication/ekar/</guid>
      <description></description>
    </item>
    
    <item>
      <title>LOREN: Logic-Regularized Reasoning for Interpretable Fact Verification</title>
      <link>https://jiangjiechen.github.io/publication/loren/</link>
      <pubDate>Tue, 22 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://jiangjiechen.github.io/publication/loren/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Probabilistic Graph Reasoning for Natural Proof Generation</title>
      <link>https://jiangjiechen.github.io/publication/probr/</link>
      <pubDate>Fri, 30 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://jiangjiechen.github.io/publication/probr/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
