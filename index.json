[{"authors":null,"categories":null,"content":"Jiangjie Chen (陈江捷) is a third-year Ph.D. candidate at Fudan University (FDU) in School of Computer Science and Technology, Shanghai, China, where he is advised by Prof. Yanghua Xiao. He is also currently a research intern at ByteDance AI Lab, where he work closely with Prof. Lei Li (now at UCSB), Dr. Hao Zhou and Dr. Changzhi Sun.\nHe is a zealous believer in reasoning over natural language and dedicated to make neural models right for the right reasons.\nHis research interests mainly lie in Explainable Natural Language Processing (ExNLP), Natural Language Generation (NLG) and Common-sense Reasoning (CSR), and particularly the deep integration of them. My previous research interests also include Knowledge Graph Construction (KGC).\n","date":1649635200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1649635200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Jiangjie Chen (陈江捷) is a third-year Ph.D. candidate at Fudan University (FDU) in School of Computer Science and Technology, Shanghai, China, where he is advised by Prof. Yanghua Xiao. He is also currently a research intern at ByteDance AI Lab, where he work closely with Prof.","tags":null,"title":"Jiangjie Chen","type":"authors"},{"authors":["Shineng Fang","Jiangjie Chen","Xinyao Shen","Yunwen Chen","Yanghua Xiao"],"categories":null,"content":"","date":1649635200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649635200,"objectID":"c51fd179c47808c4dac60cc7c33c865e","permalink":"https://jiangjiechen.github.io/publication/falcon/","publishdate":"2022-01-24T00:00:00Z","relpermalink":"/publication/falcon/","section":"publication","summary":"In a practical TableQA system, response generation is a critical module to generate a natural language description of the SQL and the execution result. Due to the complex syntax of SQL and matching issues with table content, this task is prone to produce factual errors. In this paper, we propose FALCON, a FAithfuL CONtrastive generation framework to improve the factual correctness of generated responses. FALCON forces the generation model to identify examples with factual errors in the latent space during training and takes contrastive examples into consideration during inference. We also propose two new automatic metrics to further evaluate faithfulness specialized to this task. Experimental results show FALCON brings a favorable performance improvement on both automatic and human evaluation amongst various baseline methods.","tags":["Text Generation"],"title":"FalCon: A Faithful Contrastive Framework for Response Generation in TableQA Systems","type":"publication"},{"authors":["Jiangjie Chen","Qiaoben Bao","Changzhi Sun","Xinbo Zhang","Jiaze Chen","Hao Zhou","Yanghua Xiao","Lei Li"],"categories":null,"content":"","date":1645488000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645488000,"objectID":"8f66cae4e41bfb77e4da825131a2bbf8","permalink":"https://jiangjiechen.github.io/publication/loren/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/publication/loren/","section":"publication","summary":"Interpretable fact verification with phrasal decomposition and logic regularization.","tags":["Reasoning"],"title":"LOREN: Logic-Regularized Reasoning for Interpretable Fact Verification","type":"publication"},{"authors":["Jiangjie Chen","Chun Gan","Sijie Cheng","Hao Zhou","Yanghua Xiao","Lei Li"],"categories":null,"content":"","date":1645488000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645488000,"objectID":"57120daf6bce6cc69dc265f1d02b7c2e","permalink":"https://jiangjiechen.github.io/publication/educat/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/publication/educat/","section":"publication","summary":"Creating counterfactual story endings (what-if stories) with unsupervised editing.","tags":["Reasoning","Text Generation"],"title":"Unsupervised Editing for Counterfactual Stories","type":"publication"},{"authors":["Xinyao Shen","Jiangjie Chen","Jiaze Chen","Chun Zeng","Yanghua Xiao"],"categories":null,"content":"","date":1645401600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645401600,"objectID":"fcfcb4c1f9d649a51f0cfec99b67e1ce","permalink":"https://jiangjiechen.github.io/publication/kedy/","publishdate":"2022-01-07T00:00:00Z","relpermalink":"/publication/kedy/","section":"publication","summary":"Relevant articles recommendation plays an important role in online news platforms. Directly displaying recalled articles by a search engine lacks a deep understanding of the article contents. Generating clickable queries, on the other hand, summarizes an article in various aspects, which can be henceforth utilized to better connect relevant articles. Most existing approaches for generating article queries, however, do not consider the diversity of queries or whether they are appealing enough, which are essential for boosting user experience and platform drainage. To this end, we propose a Knowledge-Enhanced Diversified QuerY Generator (KeDy), which leverages an external knowledge graph (KG) as guidance. We diversify the query generation with the information of semantic neighbors of the entities in articles. We further constrain the diversification process with entity popularity knowledge to build appealing queries that users may be more interested in. The information within KG is propagated towards more popular entities with popularity-guided graph attention. We collect a news-query dataset from the search logs of a real-world search engine. Extensive experiments demonstrate our proposed KeDy can generate more diversified and insightful related queries than several strong baselines.","tags":["Knowledge Graph","Text Generation"],"title":"Diversified Query Generation Guided with Knowledge Graph","type":"publication"},{"authors":["Qiaoben Bao","Jiangjie Chen","Linfang Liu","Jiaqing Liang","Jingping Liu","Yanghua Xiao"],"categories":null,"content":"","date":1645401600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645401600,"objectID":"1541906bfaf97f0234d89ffc98140ae9","permalink":"https://jiangjiechen.github.io/publication/scope/","publishdate":"2022-01-07T00:00:00Z","relpermalink":"/publication/scope/","section":"publication","summary":"Automatic Answer span Extraction (AE) focuses on identifying key information from paragraphs that can be asked. It has been used to facilitate downstream question generation tasks or data augmentation for question answering. Current work of AE heavily relies on the annotated answer spans from Machine Reading Comprehension (MRC) datasets. However, these methods suffer from the partial annotation problem due to the annotation protocols of MRC tasks. To tackle this problem, we propose SCOPE, a Structured Context graph network with Positive-unlabeled learning. SCOPE first represents the paragraph by constructing a graph with both syntactic and semantic edges, then adopts a unified pointer network for answer span identification. SCOPE narrows the discrenpency between AE and MRC by formulating AE as a Positive-unlabeled (PU) learning problem, thus recovering more answer spans from paragraphs. To evaluate newly extracted spans without annotation, we also present an automatic metric from the perspective of question answering and text summarization, which correlates well with human judgments. Comprehensive experiments on both AE and downstream tasks demonstrate the effectiveness of our proposed framework.","tags":["Information Extraction"],"title":"Harvesting More Answer Spans from Paragraphs beyond Annotation","type":"publication"},{"authors":["Xinyao Shen","Jiangjie Chen","Yanghua Xiao"],"categories":null,"content":"","date":1634256000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634256000,"objectID":"634c990bea69abfc3318cef06290dc18","permalink":"https://jiangjiechen.github.io/publication/keep/","publishdate":"2021-07-31T00:00:00Z","relpermalink":"/publication/keep/","section":"publication","summary":"Paraphrases refer to text with different expressions conveying the same meaning, which is usually modeled as a sequence-to-sequence (Seq2Seq) learning problem. Traditional Seq2Seq models mainly concentrate on fidelity while ignoring the diversity of paraphrases. Although recent studies begin to focus on the diversity of generated paraphrases, they either adopt inflexible control mechanisms or restrict to synonyms and topic knowledge. In this paper, we propose KnowledgE-Enhanced Paraphraser (KEEP) for diversified paraphrase generation, which leverages a commonsense knowledge graph to explicitly enrich the expressions of paraphrases. Specifically, KEEP retrieves word-level and phrase-level knowledge from an external knowledge graph, and learns to choose more related ones using graph attention mechanism. Extensive experiments on benchmarks of paraphrase generation show the strengths especially in the diversity of our proposed model compared with several strong baselines.","tags":["Knowledge Graph","Text Generation"],"title":"Diversified Paraphrase Generation with Commonsense Knowledge Graph","type":"publication"},{"authors":["Changzhi Sun","Xinbo Zhang","Jiangjie Chen","Chun Gan","Yuanbin Wu","Jiaze Chen","Hao Zhou","Lei Li"],"categories":null,"content":"","date":1627603200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627603200,"objectID":"79345889a5ef69f3485f5a7f689a808b","permalink":"https://jiangjiechen.github.io/publication/probr/","publishdate":"2021-08-30T00:00:00Z","relpermalink":"/publication/probr/","section":"publication","summary":"A novel approach for joint answer prediction and proof generation.","tags":["Reasoning"],"title":"Probabilistic Graph Reasoning for Natural Proof Generation","type":"publication"},{"authors":["Jindong Chen","Ao Wang","Jiangjie Chen","Yanghua Xiao","Zhendong Chu","Jingping Liu","Jiaqing Liang","Wei Wang"],"categories":null,"content":"","date":1565481600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565481600,"objectID":"6746a8064e018e765bad8150676eb171","permalink":"https://jiangjiechen.github.io/publication/cnprobase/","publishdate":"2019-08-11T00:00:00Z","relpermalink":"/publication/cnprobase/","section":"publication","summary":"Taxonomies play an important role in machine intelligence. However, most well-known taxonomies are in English, and non-English taxonomies, especially Chinese ones, are still very rare. In this paper, we focus on automatic Chinese taxonomy construction and propose an effective generation and verification framework to build a large-scale and high-quality Chinese taxonomy. In the generation module, we extract isA relations from multiple sources of Chinese encyclopedia, which ensures the coverage. To further improve the precision of taxonomy, we apply three heuristic approaches in verification module. As a result, we construct the largest Chinese taxonomy with high precision about 95% called CN-Probase. Our taxonomy has been deployed on Aliyun, with over 82 million API calls in six months.","tags":["Knowledge Graph","Information Extraction"],"title":"CN-Probase: A Data-driven Approach for Large-scale Chinese Taxonomy Construction","type":"publication"},{"authors":["Jiangjie Chen","Ao Wang","Haiyun Jiang","Suo Feng","Chenguang Li","Yanghua Xiao"],"categories":null,"content":"","date":1564444800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564444800,"objectID":"e3ec980cf92193ab1e303b45dd3763aa","permalink":"https://jiangjiechen.github.io/publication/hedmodgen/","publishdate":"2019-08-30T00:00:00Z","relpermalink":"/publication/hedmodgen/","section":"publication","summary":"Building head-modifier templates to constrain entity type description generation.","tags":["Knowledge Graph","Text Generation"],"title":"Ensuring Readability and Data-fidelity using Head-modifier Templates in Deep Type Description Generation","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three   A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}   Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"3c34a09a584c7e72855dabdf6593cf30","permalink":"https://jiangjiechen.github.io/slides/cnprobase/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/cnprobase/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"}]