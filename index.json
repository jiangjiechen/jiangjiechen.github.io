[{"authors":null,"categories":null,"content":"Jiangjie Chen (陈江捷) is a third-year Ph.D. candidate at Fudan University (FDU) in School of Computer Science, Shanghai, China, where he is advised by Prof. Yanghua Xiao at Knowledge Works Lab. He is also currently a research intern at ByteDance AI Lab, where he works closely with Prof. Lei Li (now at UCSB), Dr. Hao Zhou and Dr. Changzhi Sun.\nHe is a zealous believer in reasoning over natural language and dedicated to make neural models being right for the right reasons. His research interests mainly lie in Explainable NLP, Text Generation and Commonsense Reasoning, and particularly the deep integration of them. His previous research interests also include Knowledge Graph Construction (KGC).\n(  Download my resumé.)\n","date":1649635200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1649635200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Jiangjie Chen (陈江捷) is a third-year Ph.D. candidate at Fudan University (FDU) in School of Computer Science, Shanghai, China, where he is advised by Prof. Yanghua Xiao at Knowledge Works Lab.","tags":null,"title":"Jiangjie Chen","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"25060ab889b7f040577c7b4f5346542f","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Shineng Fang","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f672c6a2b4d8465bc97e6f344d6e6164","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Xinyao Shen","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"1485551e3c8c2ab314e5b62737315b83","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Ziquan Fu","type":"authors"},{"authors":["Shineng Fang","Jiangjie Chen","Xinyao Shen","Yunwen Chen","Yanghua Xiao"],"categories":null,"content":"","date":1649635200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649635200,"objectID":"c51fd179c47808c4dac60cc7c33c865e","permalink":"https://jiangjiechen.github.io/publication/falcon/","publishdate":"2022-01-24T00:00:00Z","relpermalink":"/publication/falcon/","section":"publication","summary":"In a practical TableQA system, response generation is a critical module to generate a natural language description of the SQL and the execution result. Due to the complex syntax of SQL and matching issues with table content, this task is prone to produce factual errors. In this paper, we propose FALCON, a FAithfuL CONtrastive generation framework to improve the factual correctness of generated responses. FALCON forces the generation model to identify examples with factual errors in the latent space during training and takes contrastive examples into consideration during inference. We also propose two new automatic metrics to further evaluate faithfulness specialized to this task. Experimental results show FALCON brings a favorable performance improvement on both automatic and human evaluation amongst various baseline methods.","tags":["Text Generation","Contrastive Learning","Faithfulness"],"title":"FalCon: A Faithful Contrastive Framework for Response Generation in TableQA Systems","type":"publication"},{"authors":["Jiangjie Chen","Qiaoben Bao","Changzhi Sun","Xinbo Zhang","Jiaze Chen","Hao Zhou","Yanghua Xiao","Lei Li"],"categories":null,"content":"","date":1645488000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645488000,"objectID":"8f66cae4e41bfb77e4da825131a2bbf8","permalink":"https://jiangjiechen.github.io/publication/loren/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/publication/loren/","section":"publication","summary":"Interpretable fact verification with phrasal decomposition and logic regularization.","tags":["Reasoning","Fact Verification","Explainable NLP","Faithfulness"],"title":"LOREN: Logic-Regularized Reasoning for Interpretable Fact Verification","type":"publication"},{"authors":["Jiangjie Chen","Chun Gan","Sijie Cheng","Hao Zhou","Yanghua Xiao","Lei Li"],"categories":null,"content":"","date":1645488000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645488000,"objectID":"57120daf6bce6cc69dc265f1d02b7c2e","permalink":"https://jiangjiechen.github.io/publication/educat/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/publication/educat/","section":"publication","summary":"Creating counterfactual story endings (what-if stories) with unsupervised editing.","tags":["Reasoning","Text Generation","Counterfactual Reasoning"],"title":"Unsupervised Editing for Counterfactual Stories","type":"publication"},{"authors":["Xinyao Shen","Jiangjie Chen","Jiaze Chen","Chun Zeng","Yanghua Xiao"],"categories":null,"content":"","date":1645401600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645401600,"objectID":"fcfcb4c1f9d649a51f0cfec99b67e1ce","permalink":"https://jiangjiechen.github.io/publication/kedy/","publishdate":"2022-01-07T00:00:00Z","relpermalink":"/publication/kedy/","section":"publication","summary":"Relevant articles recommendation plays an important role in online news platforms. Directly displaying recalled articles by a search engine lacks a deep understanding of the article contents. Generating clickable queries, on the other hand, summarizes an article in various aspects, which can be henceforth utilized to better connect relevant articles. Most existing approaches for generating article queries, however, do not consider the diversity of queries or whether they are appealing enough, which are essential for boosting user experience and platform drainage. To this end, we propose a Knowledge-Enhanced Diversified QuerY Generator (KeDy), which leverages an external knowledge graph (KG) as guidance. We diversify the query generation with the information of semantic neighbors of the entities in articles. We further constrain the diversification process with entity popularity knowledge to build appealing queries that users may be more interested in. The information within KG is propagated towards more popular entities with popularity-guided graph attention. We collect a news-query dataset from the search logs of a real-world search engine. Extensive experiments demonstrate our proposed KeDy can generate more diversified and insightful related queries than several strong baselines.","tags":["Knowledge Graph","Text Generation","Diversified Generation"],"title":"Diversified Query Generation Guided with Knowledge Graph","type":"publication"},{"authors":["Qiaoben Bao","Jiangjie Chen","Linfang Liu","Jiaqing Liang","Jingping Liu","Yanghua Xiao"],"categories":null,"content":"","date":1645401600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645401600,"objectID":"1541906bfaf97f0234d89ffc98140ae9","permalink":"https://jiangjiechen.github.io/publication/scope/","publishdate":"2022-01-07T00:00:00Z","relpermalink":"/publication/scope/","section":"publication","summary":"Automatic Answer span Extraction (AE) focuses on identifying key information from paragraphs that can be asked. It has been used to facilitate downstream question generation tasks or data augmentation for question answering. Current work of AE heavily relies on the annotated answer spans from Machine Reading Comprehension (MRC) datasets. However, these methods suffer from the partial annotation problem due to the annotation protocols of MRC tasks. To tackle this problem, we propose SCOPE, a Structured Context graph network with Positive-unlabeled learning. SCOPE first represents the paragraph by constructing a graph with both syntactic and semantic edges, then adopts a unified pointer network for answer span identification. SCOPE narrows the discrenpency between AE and MRC by formulating AE as a Positive-unlabeled (PU) learning problem, thus recovering more answer spans from paragraphs. To evaluate newly extracted spans without annotation, we also present an automatic metric from the perspective of question answering and text summarization, which correlates well with human judgments. Comprehensive experiments on both AE and downstream tasks demonstrate the effectiveness of our proposed framework.","tags":["Information Extraction"],"title":"Harvesting More Answer Spans from Paragraphs beyond Annotation","type":"publication"},{"authors":["Xinyao Shen","Jiangjie Chen","Yanghua Xiao"],"categories":null,"content":"","date":1634256000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634256000,"objectID":"634c990bea69abfc3318cef06290dc18","permalink":"https://jiangjiechen.github.io/publication/keep/","publishdate":"2021-07-31T00:00:00Z","relpermalink":"/publication/keep/","section":"publication","summary":"Paraphrases refer to text with different expressions conveying the same meaning, which is usually modeled as a sequence-to-sequence (Seq2Seq) learning problem. Traditional Seq2Seq models mainly concentrate on fidelity while ignoring the diversity of paraphrases. Although recent studies begin to focus on the diversity of generated paraphrases, they either adopt inflexible control mechanisms or restrict to synonyms and topic knowledge. In this paper, we propose KnowledgE-Enhanced Paraphraser (KEEP) for diversified paraphrase generation, which leverages a commonsense knowledge graph to explicitly enrich the expressions of paraphrases. Specifically, KEEP retrieves word-level and phrase-level knowledge from an external knowledge graph, and learns to choose more related ones using graph attention mechanism. Extensive experiments on benchmarks of paraphrase generation show the strengths especially in the diversity of our proposed model compared with several strong baselines.","tags":["Knowledge Graph","Text Generation","Diversified Generation"],"title":"Diversified Paraphrase Generation with Commonsense Knowledge Graph","type":"publication"},{"authors":["Changzhi Sun","Xinbo Zhang","Jiangjie Chen","Chun Gan","Yuanbin Wu","Jiaze Chen","Hao Zhou","Lei Li"],"categories":null,"content":"","date":1627603200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627603200,"objectID":"79345889a5ef69f3485f5a7f689a808b","permalink":"https://jiangjiechen.github.io/publication/probr/","publishdate":"2021-08-30T00:00:00Z","relpermalink":"/publication/probr/","section":"publication","summary":"A novel approach for joint answer prediction and proof generation.","tags":["Reasoning","Explainable NLP"],"title":"Probabilistic Graph Reasoning for Natural Proof Generation","type":"publication"},{"authors":["Jindong Chen","Ao Wang","Jiangjie Chen","Yanghua Xiao","Zhendong Chu","Jingping Liu","Jiaqing Liang","Wei Wang"],"categories":null,"content":"","date":1565481600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565481600,"objectID":"6746a8064e018e765bad8150676eb171","permalink":"https://jiangjiechen.github.io/publication/cnprobase/","publishdate":"2019-08-11T00:00:00Z","relpermalink":"/publication/cnprobase/","section":"publication","summary":"Taxonomies play an important role in machine intelligence. However, most well-known taxonomies are in English, and non-English taxonomies, especially Chinese ones, are still very rare. In this paper, we focus on automatic Chinese taxonomy construction and propose an effective generation and verification framework to build a large-scale and high-quality Chinese taxonomy. In the generation module, we extract isA relations from multiple sources of Chinese encyclopedia, which ensures the coverage. To further improve the precision of taxonomy, we apply three heuristic approaches in verification module. As a result, we construct the largest Chinese taxonomy with high precision about 95% called CN-Probase. Our taxonomy has been deployed on Aliyun, with over 82 million API calls in six months.","tags":["Knowledge Graph","Information Extraction","Taxonomy Construction"],"title":"CN-Probase: A Data-driven Approach for Large-scale Chinese Taxonomy Construction","type":"publication"},{"authors":["Jiangjie Chen","Ao Wang","Haiyun Jiang","Suo Feng","Chenguang Li","Yanghua Xiao"],"categories":null,"content":"","date":1564444800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564444800,"objectID":"e3ec980cf92193ab1e303b45dd3763aa","permalink":"https://jiangjiechen.github.io/publication/hedmodgen/","publishdate":"2019-08-30T00:00:00Z","relpermalink":"/publication/hedmodgen/","section":"publication","summary":"Building head-modifier templates to constrain entity type description generation.","tags":["Knowledge Graph","Text Generation","Constrained Generation","Faithfulness"],"title":"Ensuring Readability and Data-fidelity using Head-modifier Templates in Deep Type Description Generation","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://jiangjiechen.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":[],"title":"Example","type":"project"}]